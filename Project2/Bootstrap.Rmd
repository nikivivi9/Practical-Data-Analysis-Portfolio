
# Transformed Lasso
```{r}
# Set working directory
# Windows
setwd("C:/Users/yingx/OneDrive/Desktop/Fall 2024/PHP 2550/Data/")

# Mac
# setwd("~/Desktop/Fall 2024/PHP 2550/Data/")

# Read in data
data <- read.csv("project2.csv")

# Factor categorical variables
data[, c("abst", "Var", "BA", "sex_ps", "NHW", 
         "Black", "Hisp", "inc", "edu", "ftcd.5.mins", 
         "otherdiag", "antidepmed", "mde_curr", 
         "Only.Menthol")] <- lapply(data[, c("abst", "Var", "BA", "sex_ps", "NHW", 
                                             "Black", "Hisp", "inc", "edu", 
                                             "ftcd.5.mins", "otherdiag", "antidepmed", 
                                             "mde_curr", "Only.Menthol")], as.factor)

# Multiple imputation with m = 5
new_data <- data[, -1]
imputed_data <- mice(new_data, m = 5, method = 'pmm', seed = 2550, printFlag = FALSE)

# Extract the five imputed datasets into a list
completed_datasets <- list()
for (i in 1:5) {
  completed_datasets[[i]] <- complete(imputed_data, i)
}

for (i in 1:length(completed_datasets)) {
  completed_datasets[[i]] <- completed_datasets[[i]] %>%
    mutate(trt = as.factor(case_when(Var == 1 & BA == 1 ~ "BASC + varenicline",
                                     Var == 0 & BA == 1 ~ "BASC + placebo",
                                     Var == 1 & BA == 0 ~ "ST + varenicline",
                                     Var == 0 & BA == 0 ~ "ST + placebo",
                                     TRUE ~ NA_character_)),
           race = as.factor(case_when(Black == 0 & Hisp == 0 & NHW == 0 ~ "Unknown",
                                      Black == 1 & Hisp == 1 & NHW == 1 ~ "Mixed Race",
                                      Black == 1 & Hisp == 1 ~ "Mixed Race",
                                      Black == 1 & NHW == 1 ~ "Mixed Race",
                                      NHW == 1 & Hisp == 1 ~ "Mixed Race",
                                      Black == 1 ~ "Black",
                                      Hisp == 1 ~ "Hispanic",
                                      NHW == 1 ~ "Non-Hispanic White",
                                      TRUE ~ "Other")),
           inc = fct_recode(as.factor(inc), 
                            "Less than $20,000" = "1", 
                            "$20,000-35,000" = "2", 
                            "$35,001-50,000" = "3", 
                            "$50,001-75,000" = "4", 
                            "More than $75,000" = "5"),
           edu = fct_collapse(as.factor(edu),
                             "Some high school & Grade School" = c("1", "2"),
                             "High school graduate or GED" = "3",
                             "Some college/technical school" = "4",
                             "College graduate" = "5")) %>%
    mutate(inc = fct_relevel(inc, "Less than $20,000", "$20,000-35,000", 
                             "$35,001-50,000", "$50,001-75,000", "More than $75,000"),
           edu = fct_relevel(edu, "Some high school & Grade School", 
                             "High school graduate or GED", 
                             "Some college/technical school", "College graduate")) %>%
    mutate(trt = relevel(factor(trt), ref = "ST + placebo"))

  # Apply transformations
  completed_datasets[[i]]$shaps_score_pq1 <- asinh(completed_datasets[[i]]$shaps_score_pq1)
  completed_datasets[[i]]$hedonsum_n_pq1 <- sqrt(completed_datasets[[i]]$hedonsum_n_pq1)
  completed_datasets[[i]]$hedonsum_y_pq1 <- sqrt(completed_datasets[[i]]$hedonsum_y_pq1)
  completed_datasets[[i]]$NMR <- log(completed_datasets[[i]]$NMR)
}
```

# Bootstrap
```{r}
lasso_model_function_bootstrap <- function(data_list, n_bootstrap = 100) {
  lasso_coef <- list()
  
  for (index in seq_along(data_list)) {
    data <- data_list[[index]]
    
    # Initialize a list to store coefficients for each bootstrap iteration
    bootstrap_coef <- list()
    
    for (b in 1:n_bootstrap) {
      # Bootstrap resampling
      set.seed(2550 + b)  # Ensure reproducibility for each bootstrap iteration
      bootstrap_indices <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
      bootstrap_data <- data[bootstrap_indices, ]
      
      # Split train and test sets
      train_index <- createDataPartition(bootstrap_data$trt, p = 0.7, list = FALSE)
      train_data <- bootstrap_data[train_index, ]
      test_data <- bootstrap_data[-train_index, ]
      
      # Create fold IDs for cross-validation
      train_data$foldid <- NA
      for (trt_level in unique(train_data$trt)) {
        treatment_data <- train_data[train_data$trt == trt_level, ]
        fold_ids <- sample(rep(1:10, length.out = nrow(treatment_data)))
        train_data$foldid[train_data$trt == trt_level] <- fold_ids
      }
      
      # Define model matrix
      X <- model.matrix(abst ~ BA * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                                      bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                                      shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                                      readiness + race) +
                          Var * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                                      bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                                      shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                                      readiness + race), data = train_data)[, -1]
      y <- train_data$abst
      
      # Fit lasso with cross-validation using custom foldid
      cv_model <- cv.glmnet(X, y, family = "binomial", alpha = 1, nfolds = 10, 
                            foldid = train_data$foldid, nlambda = 100)
      best_lambda <- cv_model$lambda.min
      
      # Fit final lasso model using best lambda
      lasso_model <- glmnet(X, y, family = "binomial", alpha = 1, lambda = best_lambda)
      
      # Extract coefficients and store in a data frame
      coefficients <- as.data.frame(as.matrix(coef(lasso_model)))
      coefficients$Variable <- rownames(coefficients)
      rownames(coefficients) <- NULL
      colnames(coefficients)[1] <- "Estimates"
      
      # Store coefficients for this bootstrap iteration
      bootstrap_coef[[b]] <- coefficients
    }
    
    # Combine bootstrap coefficients into a single data frame
    combined_coef <- do.call(rbind, lapply(1:n_bootstrap, function(i) {
      bootstrap_coef[[i]]$Bootstrap <- i
      bootstrap_coef[[i]]
    }))
    
    # Store bootstrap coefficients for the current dataset
    lasso_coef[[index]] <- combined_coef
  }
  
  # Return list of coefficients for all datasets and bootstrap iterations
  return(lasso_coef)
}
```

```{r}
summarize_bootstrap <- function(data, ci_level = 0.95, threshold = 0.4) {
  # Summarize all variables including intercept
  summarized_vars <- data %>%
    group_by(Variable) %>%
    summarise(
      Mean_Estimate = mean(Estimates),
      Lower_CI = quantile(Estimates, probs = (1 - ci_level) / 2),
      Upper_CI = quantile(Estimates, probs = 1 - (1 - ci_level) / 2),
      Proportion_Selected = mean(Estimates != 0)  # Fraction of non-zero estimates
    ) %>%
    filter(Proportion_Selected > threshold)
  
  # Separate intercept and significant variables
  intercept <- summarized_vars %>%
    filter(Variable == "(Intercept)")
  
  significant_vars <- summarized_vars %>%
    filter(Variable != "(Intercept)")
  
  # Combine results
  results <- bind_rows(intercept, significant_vars)
  
  return(results)
}
```

```{r}
long_data <- function(data_list, n_bootstrap = 100) {
  trainset <- data.frame(NULL)
  testset <- data.frame(NULL)
  for (index in seq_along(data_list)) {
    data <- data_list[[index]]
    for (b in 1:n_bootstrap) {
      # Bootstrap resampling
      set.seed(2550 + b)
      
      bootstrap_indices <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
      bootstrap_data <- data[bootstrap_indices, ]
      
      # Split train and test sets
      train_index <- createDataPartition(bootstrap_data$trt, p = 0.7, list = FALSE)
      train_data <- bootstrap_data[train_index, ]
      test_data <- bootstrap_data[-train_index, ]
      
      trainset <- rbind(trainset, train_data)
      testset <- rbind(testset, test_data)
    }
  }
  return(list(train = trainset, test = testset))
}
```

```{r}
# Run the bootstrap function
boot_results <- lasso_model_function_bootstrap(completed_datasets)
combined_results <- bind_rows(boot_results, .id = "Dataset")
summary_table <- summarize_bootstrap(combined_results, ci_level = 0.95, threshold = 0.4)
long_df <- long_data(completed_datasets, n_bootstrap = 100)
trainset <- long_df$train
testset <- long_df$test
coef <- setNames(as.numeric(summary_table$Mean_Estimate), summary_table$Variable)
summary_table$sort <- c(1, 3, 3, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2)
summary_table_clean <- summary_table[order(summary_table$sort, summary_table$Variable), ] %>%
  dplyr::select(-c("sort", "Proportion_Selected")) 

write.csv(summary_table_clean, "Bootstrap_Results/summary_results.csv", row.names = FALSE)
```


```{r, out.width = "80%"}
coef <- setNames(as.numeric(summary_table$Mean_Estimate), summary_table$Variable)

X_train <- model.matrix(abst ~ BA * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                                   bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                                   shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                                   readiness + race) +
                       Var * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                              bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                              shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                              readiness + race), data = trainset)[, -1]
X_train <- data.matrix(X_train)
  
# Separate the intercept
intercept <- coef["(Intercept)"]
coef <- coef[names(coef) != "(Intercept)"]
  
# Align coefficients with model matrix
coef <- coef[names(coef) %in% colnames(X_train)]
X_train <- X_train[, names(coef), drop = FALSE]
  
# Calculate linear predictor and probabilities
linear_pred_train <- as.numeric(X_train %*% coef + intercept)
trainset$predict <- 1 / (1 + exp(-linear_pred_train)) 
  
# Calculate AUC
roc_obj_train <- roc(trainset$abst, trainset$predict)
auc_train <- auc(roc_obj_train)

X_test <- model.matrix(abst ~ BA * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                                   bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                                   shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                                   readiness + race) +
                       Var * (age_ps + sex_ps + inc + edu + ftcd_score + ftcd.5.mins +
                              bdi_score_w00 + cpd_ps + crv_total_pq1 + hedonsum_n_pq1 + hedonsum_y_pq1 +
                              shaps_score_pq1 + otherdiag + antidepmed + mde_curr + NMR + Only.Menthol +
                              readiness + race), data = testset)[, -1]
X_test <- data.matrix(X_test)
X_test <- X_test[, names(coef), drop = FALSE]

# Calculate linear predictor and probabilities
linear_pred_test <- as.numeric(X_test %*% coef + intercept)
testset$predict <- 1 / (1 + exp(-linear_pred_test)) 
  
# Calculate AUC
roc_obj_test <- roc(testset$abst, testset$predict)
auc_test <- auc(roc_obj_test)

png("Bootstrap_Results/roc_curve.png", width = 800, height = 600, res = 150)
plot(roc_obj_train, main = "ROC Curve (Bootstrap)", col = "blue", lwd = 2)
plot(roc_obj_test, add = TRUE, col = "red", lwd = 2)
text(1.05, 0.7, paste0("Train AUC: ", round(auc_train, 3)), col = "blue", cex = 0.7)
text(0.6, 0.6, paste0("Test AUC: ", round(auc_test, 3)), col = "red", cex = 0.7)
legend("bottomright", legend = c("Train", "Test"), col = c("blue", "red"), lwd = 2)


```

```{r}
trainset <- trainset %>%
  mutate(abst_num = as.numeric(as.character(trainset$abst)))
testset <- testset %>%
  mutate(abst_num = as.numeric(as.character(testset$abst)))
calibration_data <- trainset %>%
  mutate(prob_bin = cut(predict, breaks = seq(0, 1, length.out = 16), include.lowest = TRUE)) %>%
  group_by(prob_bin) %>%
  summarise(Mean_Predicted = mean(predict, na.rm = TRUE),
            Observed_Proportion = mean(abst_num, na.rm = TRUE)) %>%
  na.omit()

# Calibration plot with ideal, LM smooth, and Loess smooth
calibration_bootstrap <- ggplot(calibration_data, aes(x = Mean_Predicted, y = Observed_Proportion)) +
  geom_point(size = 2, alpha = 0.6) +  # Points for observed vs predicted
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", size = 1) +  # Ideal line
  geom_smooth(method = "lm", se = FALSE, aes(color = "LM Smooth")) +  # Linear smooth
  geom_smooth(method = "loess", se = TRUE, aes(color = "Loess Smooth")) +  # Loess smooth with CI
  labs(title = "Calibration Plot (Bootstrap)", x = "Expected Proportion",
       y = "Observed Proportion", color = "Legend") +
  scale_color_manual(name = "Legend", 
                     values = c("LM Smooth" = "blue", "Loess Smooth" = "black")) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
        legend.position = "right") +
  coord_cartesian(xlim = c(0, 0.7), ylim = c(0, 1))
ggsave("Bootstrap_Results/calibration_plot.png", plot = calibration_bootstrap, width = 8, height = 6, dpi = 300)
```



